\documentclass[11pt]{article}
\usepackage{enumitem}
\usepackage{float}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage[space]{grffile}
\usepackage{adjustbox}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{fullpage}
\usepackage{fancyhdr}
\usepackage{xparse}
\newcommand*{\boxtex}[1]{\framebox{#1}}
\newcommand{\cnum}{CM146}
\newcommand{\ced}{Fall 2018}
\newcommand{\ctitle}[3]{\title{\vspace{-0.5in}\cnum, \ced\\Problem Set #1: #2}}
\newcommand{\solution}[1]{{{\color{blue}{\bf Solution:} {#1}}}}
\NewDocumentCommand{\texcod}{mm}{%
	\texttt{\textcolor{#1}{#2}}%
}
\usepackage[usenames,dvipsnames,svgnames,table,hyperref]{xcolor}

\renewcommand*{\theenumi}{\alph{enumi}}
\renewcommand*\labelenumi{(\theenumi)}
\renewcommand*{\theenumii}{\roman{enumii}}
\renewcommand*\labelenumii{\theenumii.}

\author{Zheng Wang}
\date{\today}
\title{MATH 151A Homework 3}

\begin{document}
\maketitle

\section*{Question 1}
\begin{itemize}
	
	\item [(a)]
	Notice that we have $ x_i = 1 $, $ 2 $, $ 3 $ and $ f(x_i) = 1 $, $ \frac{1}{2} $, $ \frac{1}{3} $. Thus, it follows that the Lagrange interpolation formula is
	\begin{equation*}
	\begin{aligned}
	P(x) &= f(x_0)\frac{(x-x_1)(x-x_2)}{(x_0-x_1)(x_0-x_2)} + f(x_1)\frac{(x-x_0)(x-x_2)}{(x_1-x_0)(x_1-x_2)} + f(x_2)\frac{(x-x_0)(x-x_1)}{(x_2-x_0)(x_2-x_1)}\\
	&= 1 \cdot \frac{(x-2)(x-3)}{(1-2)(1-3)} + \frac{1}{2}\cdot\frac{(x-1)(x-3)}{(2-1)(2-3)} + \frac{1}{3}\frac{(x-1)(x-2)}{(3-1)(3-2)}\\
	& = \frac{1}{6}x^2-x+\frac{11}{6}
	\end{aligned}
	\end{equation*}
	\item [(b)]
	To use Neville's method, we first have the following:
	\[ P_0(x) = 1 \quad\quad P_1(x) = \frac{1}{2} \quad\quad P_2(x) = \frac{1}{3} \]
	Then the next iteration of Neville's method generates:
	\[ P_{0,1}(x) = \frac{P_0(x)(x-x_1) - P_1(x)(x-x_0)}{x_0 - x_1} = \frac{3}{2} - \frac{1}{2}x\]
	\[ P_{1,2}(x) = \frac{P_1(x)(x-x_2) - P_2(x)(x-x_1)}{x_1 - x_2} = \frac{5}{6} - \frac{1}{6}x \]
	Finally, we have the complete polynomial
	\[ P_{0,1,2}(x) = \frac{P_{0,1}(x)(x-x_2)-  P_{1,2}(x)(x-x_0)}{x_0-x_2} = \frac{1}{6}x^2-x+\frac{11}{6} \]
	\item[(c)]
	Use the forward difference formula:
	\[ P_{0,1,2}(x) = f[x_0] + f[x_0,x_1](x-x_0) + f[x_0,x_1,x_2](x-x_0)(x-x_1) \]
	Firstly, we have\[ f[x_0] = f(x_0) = 1 \quad\quad f[x_1] = f(x_1) = \frac{1}{2} \quad\quad f[x_2] = f(x_2) = \frac{1}{3} \]
	Secondly, we have \[ f[x_0, x_1] = \frac{f[x_1] - f[x_0]}{x_1 - x_0} = -\frac{1}{2} \quad\quad\quad f[x_1,x_2] = \frac{f[x_2] - f[x_1]}{x_2 - x_1} = -\frac{1}{6}\]
	Finally, we have $ f[x_0,x_1,x_2] = \frac{f[x_0,x_1] - f[x_1,x_2]}{x_0 - x_2} = \frac{1}{6}$. Thus, we have 
	\[ P_{0,1,2}(x) = 1  - \frac{1}{2}(x-1) + \frac{1}{6}(x-1)(x-2) =  \frac{1}{6}x^2-x+\frac{11}{6}  \]
\end{itemize}

\section*{Question 2}
We have two interval, so the cubic spline gives two cubic equation to estimate the function:
\[ S_0(x) = a_0 + b_0(x+1) + c_0(x+1)^2 + d_0(x+1)^3 \]   \[ S_1(x) = a_1 + b_1x + c_1x^2 + d_1x^3 \]
By the condition of the cubic spline, we have the following equations
\[
\begin{cases}
S_0(x_0) = a_0 = f(x_0) = 1\\
S_0(x_1) = a_0 + b_0 + c_0 + d_0 = f(x_1) = 1\\
S_1(x_1) = a_1 = f(x_1) = 1\\
S_1(x_2) = a_1 + b_1 + c_1 + d_1 = f(x_2) = 2\\
b_0 +2c_0 + 3d_0 = b_1 \quad \left(\text{by } S_0^{'}(x_1) = S_1^{'}(x_1)\right)\\
2c_0 + 6d_0 = 2c_1 \quad \left(\text{by } S_0^{''}(x_1) = S_1^{''}(x_1)\right)\\
2c_0 = 0 \quad \left(\text{by } S_0^{''}(x_0) = 0\right)\\
2c_1 + 6d_1 = 0 \quad \left(\text{by } S_1^{''}(x_2) =0 \right)
\end{cases}
\]
Solving the above equation gives us the following 
\[ S_0(x) = 1 - \frac{1}{4}(x+1) + \frac{1}{4}(x+1)^3 \]
\[ S_1(x) = 1 + \frac{1}{2}x + \frac{3}{4}x^2 - \frac{1}{4}x^3 \] 
Thus, \[ 
S(x)=
\begin{cases}
1 - \frac{1}{4}(x+1) + \frac{1}{4}(x+1)^3 \quad\quad x \in [-1,0)\\
1 + \frac{1}{2}x + \frac{3}{4}x^2 - \frac{1}{4}x^3 \quad\quad x \in [0,1]
\end{cases} \]
\pagebreak

\section*{Question 3}
We first have the following:
\begin{equation*}
\begin{aligned}
H(x_i) &= \sum_{j = 0}^{n}f(x_j)H_{n,j}(x_i) + \sum_{j =0 }^{n} f^{'}(x_j)\hat{H}_{n,j}(x_i)\\
 & = \sum_{j = 0}^{n} f(x_j)(1 -2(x_i-x_j)L^{'}_{n,j}(x_j))L^2_{n,j}(x_i) + \sum_{j =0 }^{n} f^{'}(x_j)((x_i-x_j)L^2_{n,j}(x_i))\\
\end{aligned}
\end{equation*}
Since we have $ L^2_{n,j}(x_i) = 0 $ if $ j \ne i $ and $ L^2_{n,j}(x_i) = 1 $ if $ j = i $. Thus, $ f^{'}(x_j)((x_i-x_j)L^2_{n,j}(x_i)) = 0 \quad \forall x_i $ and $ (1 -2(x_i-x_j)L^{'}_{n,j}(x_j))L^2_{n,j}(x_i) $ equals to 0 when $ j \ne i $ and equals to 1 when $ j = i $. Therefore, $H(x_i) = f(x_i)\times 1 + 0 = f(x_i)$.\\\\
Then, we have 
\[ H'(x) = \sum_{j = 0}^{n}f(x_j)H^{'}_{n,j}(x) + \sum_{j =0 }^{n} f^{'}(x_j)\hat{H}^{'}_{n,j}(x) \] 
Since $ H^{'}_{n,j}(x) = 2[1-2(x-x_j)L^{'}_{n,j}(x_j)]L_{n,j}(x)L^{'}_{n,j}(x) -2L_{n,j}^{'}(x_j)L_{n,j}^{2}(x) $,\\
$ \hat{H}^{'}_{n,j}(x) = L_{n,j}^2(x) + 2L_{n,j}(x)L^{'}_{n,j}(x)(x-x_j) $. \\
We have $H^{'}_{n,j}(x_i) = 0$ for all $ x_i $; $ \hat{H}_{n,j}^{'}(x_i) = 0 $ when $ i \ne j $ and $ \hat{H}_{n,j}^{'}(x_i) = 1 $ when $ j = i $.
Thus, $ H^{'}(x_i) = f^{'}(x_i) \times 1 + 0 = f^{'}(x_i) $. \hfill $ \blacksquare $


\section*{Question 4}
\begin{itemize}
	\item [(a)]
	Suppose that we have $ x_1 = x_0 -h $ and $ x_2 = x_0 + h $
	\begin{equation*}
	\begin{aligned}
	P(x) &= f(x_0)\frac{(x-x_1)(x-x_2)}{(x_0-x_1)(x_0-x_2)} + f(x_1)\frac{(x-x_0)(x-x_2)}{(x_1-x_0)(x_1-x_2)} + f(x_2)\frac{(x-x_0)(x-x_1)}{(x_2-x_0)(x_2-x_1)}\\
	&= f(x_0) \cdot \frac{(x-x_0 + h)(x-x_0-h)}{-h^2} + f(x_0 - h)\cdot\frac{(x-x_0)(x-x_0-h)}{2h^2}\\
	& + f(x_0 + h)\frac{(x-x_0)(x-x_0 + h)}{2h^2}
	\end{aligned}
	\end{equation*}
	
	\item[(b)]
	The error term is $ \displaystyle E(x) = \frac{f^{'''}(\xi(x))}{6}(x-x_0)(x-x_0+h)(x-x_0-h) $, where $ \xi(x) \in [x_0-h,x_0 + h]$.
	
	\item [(c)]
	We have $ f^{'}(x) = P^{'}(x) + E^{'}(x) $. Thus, it suffice to derive $ P^{'}(x)\Bigr|_{x=x_0} $ and $ E^{'}(x)\Bigr|_{x=x_0} $ to find $ f^{'}(x_0) $.
	\begin{equation*}
	\begin{aligned}
	 P^{'}(x)\Bigr|_{x= x_0} &= f(x_0) \frac{2x_0 - x_1-x_2}{(x_0-x_1)(x_0-x_2)} + f(x_1)\frac{2x_0 -x_0 - x_2}{(x_1-x_0)(x_1-x_2)} + f(x_2)\frac{2x_0 - x_0 -x_1}{(x_2-x_0)(x_2-x_1)}\\
	 &= 0 - \frac{f(x_0 - h)}{2h} + \frac{f(x_0+h)}{2h}\\
	 &=\frac{1}{2h}\left(f(x_0+h) - f(x_0-h)\right)
	\end{aligned}
	\end{equation*}
	Also, we have $ \displaystyle E^{'}(x)\Bigr|_{x= x_0} = -h^2\cdot \frac{f^{'''}(\xi(x_0))}{6} $\\
	Thus, \boxtex{$ \displaystyle f^{'}(x_0) = \frac{1}{2h}\left(f(x_0+h) - f(x_0-h)\right) - \frac{h^2}{6}f^{'''}(\xi(x_0))  $}, where $ \xi(x) \in [x_0-h,x_0 + h]$.
	
	\item [(d)]
	The statement is \boxtex{TRUE}. This is because if $ f $ is a polynomial of degree less or equal 2, then $\displaystyle f^{'''}(x) = 0 \quad \forall x \in  \mathbb{R} $, then, $ E^{'}(x_0) = 0 $ and $ f^{'}(x_0) = P^{'}(x_0) $.
	
	\item [(e)]
	The error bound for estimating $ f'(x_0) $ is $ \displaystyle |E| = \left| E^{'}(x)\Bigr|_{x= x_0} \right| = h^2\cdot \frac{f^{'''}(\xi(x_0))}{6} $. If we in addition assume that $ f^{'''}(\xi(x_0)) \le M  $, then, we have $\displaystyle |E| \le \frac{M\cdot h^2}{6} $.\\ 
	In general case (estimating $ f'(x) $ for any $ x $), we have \[ |E| = \frac{3x^2 + 3y^2 - h^2 - 6xx_0}{6}f^{'''}(\xi(x)) + \frac{(x-x_0)(x-x_0+h)(x-x_0-h)}{6}\cdot \left( f^{'''}(\xi(x)) \right)' \]
\end{itemize}

\section*{Question 5 (Coding)}
See file hw3\_5.m for detail.\\\\
The following is a copy of the code:
\begin{verbatim}
% MATH 151A 
% Homework 3, Question 5
% Wang, Zheng

%% input vector:
x = input('Please input a vector of x_i (e.g. [1 2 3]):\n');
y = input('Please input a vector of f(x_i) (e.g. [0 1 0]): \n');
if size(x,2) ~= size(y,2)
    error('x and y must be of same length!')
end

%% input a
a = input('Please input value of a:');

%% calculation and output
fprintf('P(a) = %12.8f\n',eval_lag_poly(x,y,a))

%% Function Toolbox
function fx = eval_lag_poly(x, y, a)
    x = x';
    y = y';
    n = size(x,1);
    X = repmat(x,1,n);
    for j=1:n
        X(:,j) = X(:,j).^(j-1);
    end
    coef = X\y;
    A = repmat(a, 1, n);
    for i=1:n
        A(:,i) = A(:,i).^(i-1);
    end
    fx = A*coef;
end

\end{verbatim}

\end{document}